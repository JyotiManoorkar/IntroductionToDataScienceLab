{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17949eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 1 : \n",
    "#Implementation of the Data Science Lifecycle and \n",
    "#Data Type Classification Using the Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2021fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "# for data manipulation and analysis\n",
    "# for numerical operations (used here if needed)\n",
    "\n",
    "\n",
    "\n",
    "# Importing the pandas library and assigning it the alias 'pd'\n",
    "# pandas is one of the most widely used libraries in data science for working with structured data.\n",
    "# It provides two primary data structures:\n",
    "# - Series: a one-dimensional array (like a column in Excel or a list with labels)\n",
    "# - DataFrame: a two-dimensional table with labeled rows and columns (like a spreadsheet or SQL table)\n",
    "# Common pandas features include:\n",
    "# - Reading data from CSV, Excel, SQL, JSON, and more\n",
    "# - Cleaning and preprocessing data (e.g., handling missing values, renaming columns)\n",
    "# - Filtering, grouping, and aggregating data\n",
    "# - Merging, joining, and reshaping datasets\n",
    "# - Performing descriptive statistics and exporting clean data\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the numpy library and assigning it the alias 'np'\n",
    "# numpy is the foundational library for numerical and scientific computing in Python.\n",
    "# It is especially useful for:\n",
    "# - Creating and manipulating numerical arrays (1D, 2D, or multidimensional)\n",
    "# - Performing fast element-wise operations and mathematical functions\n",
    "# - Handling missing values using np.nan, np.isnan, np.nanmean, etc.\n",
    "# - Generating random numbers (important in simulations, modeling, and ML)\n",
    "# - Serving as a backend for other libraries like pandas, scikit-learn, TensorFlow, and more\n",
    "# In data science, numpy is often used behind the scenes for speed and efficiency\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4c947bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# 1. DATA COLLECTION\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Importing the Titanic dataset using pandas\n",
    "# This step loads structured data from a CSV (Comma-Separated Values) file into a DataFrame.\n",
    "# A DataFrame is similar to a table in Excel or a SQL database: it has rows (records) and columns (features).\n",
    "# 'read_csv()' is one of pandas' most commonly used functions to read tabular data.\n",
    "# NOTE:\n",
    "# - Make sure the file path is correct and that the file exists at that location.\n",
    "# - On Windows, use double backslashes (\\\\) or a raw string (prefix with 'r') to avoid errors with escape characters.\n",
    "# - If the file is in the same directory as your script, you can simply use the filename (e.g., \"Titanic.csv\").\n",
    "df = pd.read_csv(\"C:\\MITADT\\ISDL\\Lab 1\\Titanic.csv\")  # Load CSV into a DataFrame\n",
    "\n",
    "# Display the first 5 rows of the dataset\n",
    "# 'head()' is used to quickly inspect the data.\n",
    "# This helps you:\n",
    "# - Understand what kind of information is present (e.g., names, ages, ticket class, survival status)\n",
    "# - Identify column names and types of data (numerical, categorical, text)\n",
    "# - Spot any immediate issues like missing data, inconsistent formatting, or irrelevant columns\n",
    "# It’s a key step before proceeding with data cleaning or analysis.\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())  # Default shows 5 rows; you can pass a number (e.g., head(10)) to see more rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c030456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types and non-null counts:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# 2. DATA TYPE CLASSIFICATION\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Displaying basic information about the dataset using df.info()\n",
    "# This method provides a concise summary of the DataFrame, including:\n",
    "# - Total number of entries (rows)\n",
    "# - Number of non-null (non-missing) values in each column\n",
    "# - Data type of each column (e.g., int64, float64, object)\n",
    "# - Memory usage of the DataFrame\n",
    "\n",
    "# WHY THIS IS IMPORTANT:\n",
    "# - Helps identify which columns contain missing data\n",
    "# - Reveals data types (very important for further processing):\n",
    "#     • 'object' typically means text/categorical data\n",
    "#     • 'int64' and 'float64' are numerical (used in calculations and modeling)\n",
    "#     • 'bool' for binary values\n",
    "#     • 'datetime64' if dates are present (can be parsed later if needed)\n",
    "# - Useful for detecting unexpected types (e.g., a numeric-looking column loaded as object due to formatting issues)\n",
    "\n",
    "print(\"\\nData types and non-null counts:\")\n",
    "print(df.info())  # Outputs structure and metadata about the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b48aec79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Measurement Scale Classification of Each Column:\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------\n",
    "# Structure-based Classification:\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# This is a structured dataset.\n",
    "# Structured data is organized into rows and columns, much like a table in a database or a spreadsheet.\n",
    "# Each column represents a feature (also called a variable or attribute),\n",
    "# and each row represents an observation (or record, like a single passenger on the Titanic).\n",
    "# Structured data is easily processed using pandas and is ideal for statistical analysis and machine learning models.\n",
    "\n",
    "# Example of structured format:\n",
    "# | PassengerId | Name        | Age | Sex   | Survived |\n",
    "# |-------------|-------------|-----|-------|----------|\n",
    "# | 1           | John Smith  | 22  | male  | 0        |\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Measurement Scale-based Classification (manual):\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# Variables in datasets can also be classified by their *level of measurement* (or scale).\n",
    "# There are four common types of scales:\n",
    "# - Nominal: Categorical variables with no inherent order (e.g., Sex, Embarked)\n",
    "# - Ordinal: Categorical variables with a clear order or ranking (e.g., Pclass = 1st, 2nd, 3rd)\n",
    "# - Interval: Numeric data with meaningful differences, but no true zero (e.g., Temperature in Celsius)\n",
    "# - Ratio: Numeric data with meaningful zero and ratios (e.g., Age, Fare)\n",
    "\n",
    "print(\"\\nMeasurement Scale Classification of Each Column:\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c8edc0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Summary of Column Types and Scales:\n",
      "    Column Name Data Type (Pandas) Measurement Scale\n",
      "0   PassengerId              int64           Nominal\n",
      "1      Survived              int64           Nominal\n",
      "2        Pclass              int64           Ordinal\n",
      "3          Name             object           Nominal\n",
      "4           Sex             object           Nominal\n",
      "5           Age            float64             Ratio\n",
      "6         SibSp              int64             Ratio\n",
      "7         Parch              int64             Ratio\n",
      "8        Ticket             object           Nominal\n",
      "9          Fare            float64             Ratio\n",
      "10        Cabin             object           Nominal\n",
      "11     Embarked             object           Nominal\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Creating a Summary Table: Column Names, Data Types, and Scales\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Step 1: Manually define the measurement scale for each column\n",
    "# This uses domain knowledge of the Titanic dataset and data types.\n",
    "# It's crucial for deciding how to preprocess each feature (e.g., encoding categorical variables).\n",
    "# defines a Python dictionary called measurement_scale, which is used to manually classify each column in the Titanic dataset\n",
    "# based on its level of measurement in statistics. \n",
    "#This classification helps in choosing the correct preprocessing, analysis, and modeling techniques.\n",
    "measurement_scale = {\n",
    "    'PassengerId': 'Nominal',   # Acts as a unique ID for each passenger\n",
    "                                # Treated as a label, not used for modeling\n",
    "\n",
    "    'Survived': 'Nominal',      # Binary categorical variable: 0 = No, 1 = Yes\n",
    "                                # Can be treated as categorical for classification tasks\n",
    "\n",
    "    'Pclass': 'Ordinal',        # Passenger class: 1st > 2nd > 3rd\n",
    "                                # Ranked categories with implied socioeconomic status\n",
    "\n",
    "    'Name': 'Nominal',          # Passenger names (textual, unique identifiers)\n",
    "                                # Not useful as-is for modeling; may be used to extract titles\n",
    "\n",
    "    'Sex': 'Nominal',           # Categorical variable: male, female\n",
    "                                # Needs encoding before modeling\n",
    "\n",
    "    'Age': 'Ratio',             # Continuous numeric variable with a true zero\n",
    "                                # Can be used directly in mathematical operations or scaling\n",
    "\n",
    "    'SibSp': 'Ratio',           # Count of siblings/spouses aboard\n",
    "                                # Whole number count, meaningful zero\n",
    "\n",
    "    'Parch': 'Ratio',           # Count of parents/children aboard\n",
    "                                # Also a count feature with a true zero\n",
    "\n",
    "    'Ticket': 'Nominal',        # Ticket number/code\n",
    "                                # No meaningful numeric or ordered structure\n",
    "\n",
    "    'Fare': 'Ratio',            # Fare paid, continuous numerical value\n",
    "                                # Can be used for analysis, needs scaling for some models\n",
    "\n",
    "    'Cabin': 'Nominal',         # Cabin identifiers (e.g., C85, E46)\n",
    "                                # Textual and highly missing — often dropped or simplified\n",
    "\n",
    "    'Embarked': 'Nominal'       # Port of embarkation: C (Cherbourg), Q (Queenstown), S (Southampton)\n",
    "                                # Categorical variable with no natural order\n",
    "}\n",
    "\n",
    "# Step 2: Create a DataFrame that summarizes:\n",
    "# - Column Name\n",
    "# - Pandas-inferred Data Type (e.g., object, float64, int64)\n",
    "# - Manually assigned Measurement Scale\n",
    "# Create a Summary Table (column_info) of Titanic Dataset\n",
    "# -------------------------------------------------------------\n",
    "# This code creates a new DataFrame that summarizes key metadata\n",
    "# for each column in your dataset: column name, data type, and\n",
    "# measurement scale (Nominal, Ordinal, or Ratio).\n",
    "# This helps in understanding how to process each column correctly.\n",
    "\n",
    "column_info = pd.DataFrame({\n",
    "    \n",
    "    # Column Name: List of all column names from the original DataFrame (df)\n",
    "    # Example: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', ...]\n",
    "    'Column Name': df.columns,\n",
    "\n",
    "    # Data Type (Pandas): Shows the type of data in each column, as inferred by pandas.\n",
    "    # These include:\n",
    "    # - int64: integers\n",
    "    # - float64: decimal numbers\n",
    "    # - object: strings (text)\n",
    "    # - category: optimized type for categorical variables\n",
    "    'Data Type (Pandas)': df.dtypes.values,\n",
    "\n",
    "    # Measurement Scale: Manually defined scale (Nominal, Ordinal, or Ratio)\n",
    "    # This comes from your earlier measurement_scale dictionary.\n",
    "    # It tells you how each column should be interpreted statistically:\n",
    "    # - Nominal: Categories without order (e.g., Sex, Embarked)\n",
    "    # - Ordinal: Categories with order (e.g., Pclass)\n",
    "    # - Ratio: Numeric data with a meaningful zero (e.g., Age, Fare)\n",
    "    'Measurement Scale': [measurement_scale[col] for col in df.columns]\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "#  Why this is useful:\n",
    "# - Helps you understand your data structure\n",
    "# - Guides preprocessing (e.g., encoding, scaling, dropping)\n",
    "# - Provides clear documentation of how your data is interpreted\n",
    "\n",
    "# Step 3: Display the summary table\n",
    "# This makes it easy to:\n",
    "# - Check which columns are numerical or categorical\n",
    "# - Decide how to handle each column during preprocessing\n",
    "print(\"\\n Summary of Column Types and Scales:\")\n",
    "print(column_info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bf23f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in each column:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# 3. DATA PREPROCESSING\n",
    "# ---------------------------------------------\n",
    "\n",
    "# a) Identifying Missing Values\n",
    "\n",
    "# Missing values (NaNs) can cause errors or misleading results during analysis and modeling.\n",
    "# It's important to find out which columns have missing data and how many entries are affected.\n",
    "# The method 'isnull()' returns a DataFrame of the same shape as df,\n",
    "# with True where values are missing (NaN) and False otherwise.\n",
    "# By chaining 'sum()', we get the total count of missing values per column.\n",
    "\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Understanding missing data helps you decide:\n",
    "# - Whether to remove rows or columns with missing data\n",
    "# - Whether to fill missing values with statistics (mean, median, mode)\n",
    "# - Whether to apply more advanced imputation methods or flag missingness\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09ed3c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset after preprocessing:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Embarked  \n",
      "0      0         A/5 21171   7.2500        S  \n",
      "1      0          PC 17599  71.2833        C  \n",
      "2      0  STON/O2. 3101282   7.9250        S  \n",
      "3      0            113803  53.1000        S  \n",
      "4      0            373450   8.0500        S  \n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# 3. DATA PREPROCESSING \n",
    "# ---------------------------------------------\n",
    "\n",
    "# b) Handling Missing Values\n",
    "\n",
    "# Fill missing values in 'Age' column with the median value of 'Age'\n",
    "# Why median?\n",
    "# - Age data is often skewed and may contain outliers.\n",
    "# - Median is the middle value and is robust to outliers, unlike the mean.\n",
    "# - Filling missing 'Age' values prevents losing rows during analysis and modeling.\n",
    "\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)  \n",
    "\n",
    "# inplace=True means changes are applied directly to df without needing reassignment.\n",
    "\n",
    "# Fill missing values in 'Embarked' column with the mode (most frequent category)\n",
    "# Why mode for categorical data?\n",
    "# - 'Embarked' represents categories (ports of embarkation: C, Q, S).\n",
    "# - Replacing missing values with the most common category helps retain data without biasing much.\n",
    "\n",
    "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# mode() returns a Series of modes; [0] extracts the top mode value.\n",
    "\n",
    "# The 'Cabin' column contains many missing values (~75% missing in Titanic dataset).\n",
    "# Why drop it?\n",
    "# - Imputing so many missing values may introduce noise or bias.\n",
    "# - The column may not provide significant predictive power in its raw form.\n",
    "# - Dropping reduces dimensionality and simplifies preprocessing.\n",
    "\n",
    "df.drop('Cabin', axis=1, inplace=True)\n",
    "\n",
    "# axis=1 specifies dropping a column (axis=0 would drop rows).\n",
    "\n",
    "# c) Basic Data Cleaning and Formatting\n",
    "\n",
    "# Convert 'Sex' and 'Embarked' columns to categorical data type.\n",
    "# Benefits:\n",
    "# - Saves memory compared to using 'object' dtype (strings).\n",
    "# - Explicitly marks these columns as categorical, which helps some pandas functions and ML algorithms.\n",
    "# - Some ML libraries detect 'category' dtype and optimize internally.\n",
    "df['Sex'] = df['Sex'].astype('category')\n",
    "df['Embarked'] = df['Embarked'].astype('category')\n",
    "\n",
    "# Clean column names by stripping whitespace (leading or trailing spaces).\n",
    "# Why?\n",
    "# - Accidental spaces can cause errors when selecting columns by name.\n",
    "# - Ensures consistent column naming for reliable downstream processing.\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame to verify all preprocessing steps.\n",
    "print(\"\\nDataset after preprocessing:\")\n",
    "print(df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d98c5157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Remaining missing values after preprocessing:\n",
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Final check for any remaining missing values\n",
    "print(\"\\nRemaining missing values after preprocessing:\")\n",
    "print(df.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07df1c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated Data Types after cleaning:\n",
      "PassengerId       int64\n",
      "Survived          int64\n",
      "Pclass            int64\n",
      "Name             object\n",
      "Sex            category\n",
      "Age             float64\n",
      "SibSp             int64\n",
      "Parch             int64\n",
      "Ticket           object\n",
      "Fare            float64\n",
      "Embarked       category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display updated data types\n",
    "print(\"\\nUpdated Data Types after cleaning:\")\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27afa351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d878452d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd73071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdcccf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
